n <- 2
m<-1000
samples <- metropolis_hastings(p_scenario3, m, c(1.4, -0.76), 2*diag(2), 2)
#plot(samples)
#persp(den3d, box=FALSE)
den3d <- kde2d(samples[,1], samples[,2])
plot_ly(x=den3d$x, y=den3d$y, z=den3d$z) %>% add_surface()
acf(samples, lag.max = 100)
print("MCMC standard error:")
mcse(samples)$se #returns estimate of the mean and
print("MCMC EES by components:")
ess(samples)
#m * (var(samples) / m) / (mcse(samples)$se)^2 # diy ESS: sample size times ratio of MC and MCMC error
g1 <- ggplot( data.frame(ID = c(1:m,1:m), x = c(samples[,1], samples[,2]), dim=c(rep('dim_1',m), rep('dim_2',m)) ), aes(x = ID, y = x)) +
geom_line()+
ggtitle("Trace plot of both dimensions") +
facet_wrap(~dim)
plot(g1)
paste0("Mean of samples (",mean(samples[,1]),",",mean(samples[,2]),")")
n <- 2
m<-1000
samples <- metropolis_hastings(p_scenario3, m, c(1.4, -0.76), 0.5*diag(2), 2)
#plot(samples)
#persp(den3d, box=FALSE)
den3d <- kde2d(samples[,1], samples[,2])
plot_ly(x=den3d$x, y=den3d$y, z=den3d$z) %>% add_surface()
acf(samples, lag.max = 100)
print("MCMC standard error:")
mcse(samples)$se #returns estimate of the mean and
print("MCMC EES by components:")
ess(samples)
#m * (var(samples) / m) / (mcse(samples)$se)^2 # diy ESS: sample size times ratio of MC and MCMC error
g1 <- ggplot( data.frame(ID = c(1:m,1:m), x = c(samples[,1], samples[,2]), dim=c(rep('dim_1',m), rep('dim_2',m)) ), aes(x = ID, y = x)) +
geom_line()+
ggtitle("Trace plot of both dimensions") +
facet_wrap(~dim)
plot(g1)
paste0("Mean of samples (",mean(samples[,1]),",",mean(samples[,2]),")")
n <- 2
m<-1000
samples <- metropolis_hastings(p_scenario3, m, c(1.4, -0.76), 1*diag(2), 2)
#plot(samples)
#persp(den3d, box=FALSE)
den3d <- kde2d(samples[,1], samples[,2])
plot_ly(x=den3d$x, y=den3d$y, z=den3d$z) %>% add_surface()
acf(samples, lag.max = 100)
print("MCMC standard error:")
mcse(samples)$se #returns estimate of the mean and
print("MCMC EES by components:")
ess(samples)
#m * (var(samples) / m) / (mcse(samples)$se)^2 # diy ESS: sample size times ratio of MC and MCMC error
g1 <- ggplot( data.frame(ID = c(1:m,1:m), x = c(samples[,1], samples[,2]), dim=c(rep('dim_1',m), rep('dim_2',m)) ), aes(x = ID, y = x)) +
geom_line()+
ggtitle("Trace plot of both dimensions") +
facet_wrap(~dim)
plot(g1)
paste0("Mean of samples (",mean(samples[,1]),",",mean(samples[,2]),")")
n <- 2
m<-1000
samples <- metropolis_hastings(p_scenario3, m, c(1.4, -0.76), 0.2*diag(2), 2)
#plot(samples)
#persp(den3d, box=FALSE)
den3d <- kde2d(samples[,1], samples[,2])
plot_ly(x=den3d$x, y=den3d$y, z=den3d$z) %>% add_surface()
acf(samples, lag.max = 100)
print("MCMC standard error:")
mcse(samples)$se #returns estimate of the mean and
print("MCMC EES by components:")
ess(samples)
#m * (var(samples) / m) / (mcse(samples)$se)^2 # diy ESS: sample size times ratio of MC and MCMC error
g1 <- ggplot( data.frame(ID = c(1:m,1:m), x = c(samples[,1], samples[,2]), dim=c(rep('dim_1',m), rep('dim_2',m)) ), aes(x = ID, y = x)) +
geom_line()+
ggtitle("Trace plot of both dimensions") +
facet_wrap(~dim)
plot(g1)
paste0("Mean of samples (",mean(samples[,1]),",",mean(samples[,2]),")")
n <- 2
m<-1000
samples <- metropolis_hastings(p_scenario3, m, c(1.4, -0.76), 0.02*diag(2), 2)
#plot(samples)
#persp(den3d, box=FALSE)
den3d <- kde2d(samples[,1], samples[,2])
plot_ly(x=den3d$x, y=den3d$y, z=den3d$z) %>% add_surface()
acf(samples, lag.max = 100)
print("MCMC standard error:")
mcse(samples)$se #returns estimate of the mean and
print("MCMC EES by components:")
ess(samples)
#m * (var(samples) / m) / (mcse(samples)$se)^2 # diy ESS: sample size times ratio of MC and MCMC error
g1 <- ggplot( data.frame(ID = c(1:m,1:m), x = c(samples[,1], samples[,2]), dim=c(rep('dim_1',m), rep('dim_2',m)) ), aes(x = ID, y = x)) +
geom_line()+
ggtitle("Trace plot of both dimensions") +
facet_wrap(~dim)
plot(g1)
paste0("Mean of samples (",mean(samples[,1]),",",mean(samples[,2]),")")
n <- 2
m<-1000
samples <- metropolis_hastings(p_scenario3, m, c(1.4, -0.76), 0.002*diag(2), 2)
#plot(samples)
#persp(den3d, box=FALSE)
den3d <- kde2d(samples[,1], samples[,2])
plot_ly(x=den3d$x, y=den3d$y, z=den3d$z) %>% add_surface()
acf(samples, lag.max = 100)
print("MCMC standard error:")
mcse(samples)$se #returns estimate of the mean and
print("MCMC EES by components:")
ess(samples)
#m * (var(samples) / m) / (mcse(samples)$se)^2 # diy ESS: sample size times ratio of MC and MCMC error
g1 <- ggplot( data.frame(ID = c(1:m,1:m), x = c(samples[,1], samples[,2]), dim=c(rep('dim_1',m), rep('dim_2',m)) ), aes(x = ID, y = x)) +
geom_line()+
ggtitle("Trace plot of both dimensions") +
facet_wrap(~dim)
plot(g1)
paste0("Mean of samples (",mean(samples[,1]),",",mean(samples[,2]),")")
n <- 2
m<-1000
samples <- metropolis_hastings(p_scenario3, m, c(1.4, -0.76), 0.008*diag(2), 2)
#plot(samples)
#persp(den3d, box=FALSE)
den3d <- kde2d(samples[,1], samples[,2])
plot_ly(x=den3d$x, y=den3d$y, z=den3d$z) %>% add_surface()
acf(samples, lag.max = 100)
print("MCMC standard error:")
mcse(samples)$se #returns estimate of the mean and
print("MCMC EES by components:")
ess(samples)
#m * (var(samples) / m) / (mcse(samples)$se)^2 # diy ESS: sample size times ratio of MC and MCMC error
g1 <- ggplot( data.frame(ID = c(1:m,1:m), x = c(samples[,1], samples[,2]), dim=c(rep('dim_1',m), rep('dim_2',m)) ), aes(x = ID, y = x)) +
geom_line()+
ggtitle("Trace plot of both dimensions") +
facet_wrap(~dim)
plot(g1)
paste0("Mean of samples (",mean(samples[,1]),",",mean(samples[,2]),")")
n <- 2
m<-1000
samples <- metropolis_hastings(p_scenario3, m, c(1.4, -0.76), 0.01*diag(2), 2)
#plot(samples)
#persp(den3d, box=FALSE)
den3d <- kde2d(samples[,1], samples[,2])
plot_ly(x=den3d$x, y=den3d$y, z=den3d$z) %>% add_surface()
acf(samples, lag.max = 100)
print("MCMC standard error:")
mcse(samples)$se #returns estimate of the mean and
print("MCMC EES by components:")
ess(samples)
#m * (var(samples) / m) / (mcse(samples)$se)^2 # diy ESS: sample size times ratio of MC and MCMC error
g1 <- ggplot( data.frame(ID = c(1:m,1:m), x = c(samples[,1], samples[,2]), dim=c(rep('dim_1',m), rep('dim_2',m)) ), aes(x = ID, y = x)) +
geom_line()+
ggtitle("Trace plot of both dimensions") +
facet_wrap(~dim)
plot(g1)
paste0("Mean of samples (",mean(samples[,1]),",",mean(samples[,2]),")")
acf(samples, lag.max = 200)
n <- 10
m<-1000
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.01*diag(10), 10)
n <- 11
m<-1000
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.01*diag(11), 11)
p_scenario1 <- function(x){
mu <- c(0,0)
sigma <- matrix(c(1, 0, 0, 1), ncol = 2)
return (dmvnorm(x, mu, sigma))
}
p_scenario2 <- function(x) {
B <- 0.05
exp( (-(x[1]^2)/200- 0.5 * (x[2]+ B * x[1]^2 - 100*B)^2 ) )
}
#x are just the fit coefficients
p_scenario3 <- function(x){
df <- read.csv("datset.csv", header = TRUE, sep = ",")
#model  <- glm(y ~ X2, family="binomial", data=df)
#y_pred <- predict(model, data.frame(X2=df[,2]), type="response")
y_pred <- as.matrix(df[,1:2]) %*% x
y_pred <- 1/(1+exp(-y_pred))
return (prod(lr_likelihood(df$y, y_pred)))
}
p_scenario4 <- function(x){
df <- read.csv("datset.csv", header = TRUE, sep = ",")
#model  <- glm(y ~ X2+X3+X4+X5+X6+X7+X8+X9+X10+X11, family="binomial", data=df)
#y_pred <- predict(model, df[,2:11], type="response")
y_pred <- as.matrix(df[,1:11]) %*% x
return (prod(lr_likelihood(df$y, y_pred)))
}
p_scenario_test <- function(x){
return (0.1)
}
p_scenario3_mean <- function(){
df <- read.csv("datset.csv", header = TRUE, sep = ",")
model  <- glm(y ~ X2, family="binomial", data=df)
#print(summary(model))
#y_pred <- predict(model, data.frame(X2=df[,2]), type="response")
return (model$coefficients)
}
p_scenario4_mean <- function(){
df <- read.csv("datset.csv", header = TRUE, sep = ",")
model  <- glm(y ~ X2+X3+X4+X5+X6+X7+X8+X9+X10+X11, family="binomial", data=df)
#print(summary(model))
#y_pred <- predict(model, data.frame(X2=df[,2]), type="response")
return (model$coefficients)
}
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.01*diag(11), 11)
n <- 11
m<-1000
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.01*diag(11), 11)
f = p_scenario4
m = 1000
x0 <- c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47)
cov <- 0.01*diag(11)
dimensions = 11
#New code
samples <- samples <- matrix(vector('integer', 2*m), ncol = dimensions)
#New code
samples <- matrix(vector('integer', 2*m), ncol = dimensions)
samples
nrow(samples)
m
2*m
#New code
samples <- matrix(vector('integer', dimensions*m), ncol = dimensions)
samples[1,] <- x0
for(i in 2:m){
prev_x <-  samples[i-1,]
new_x <- rmvnorm(1, prev_x, cov)
#print(t(prev_x))
alpha <- min(1, (f(c(new_x))*dmvnorm(new_x, prev_x, cov))/(f(c(prev_x))*dmvnorm(prev_x, new_x, cov)) )
u <- runif(1)
if (u<=alpha){
samples[i,]<-new_x
}
else{
samples[i,]<-prev_x
}
}
orev_x
prev_x
new_x <- rmvnorm(1, prev_x, cov)
new_x
#print(t(prev_x))
alpha <- min(1, (f(c(new_x))*dmvnorm(new_x, prev_x, cov))/(f(c(prev_x))*dmvnorm(prev_x, new_x, cov)) )
alpha
u <- runif(1)
if (u<=alpha){
samples[i,]<-new_x
}
else{
for(i in 2:m){
prev_x <-  samples[i-1,]
new_x <- rmvnorm(1, prev_x, cov)
#print(t(prev_x))
alpha <- min(1, (f(c(new_x))*dmvnorm(new_x, prev_x, cov))/(f(c(prev_x))*dmvnorm(prev_x, new_x, cov)) )
u <- runif(1)
if (u<=alpha){
samples[i,]<-new_x
}
else{
samples[i,]<-prev_x
}
}
for(i in 2:m){
prev_x <-  samples[i-1,]
new_x <- rmvnorm(1, prev_x, cov)
#print(t(prev_x))
alpha <- min(1, (f(c(new_x))*dmvnorm(new_x, prev_x, cov))/(f(c(prev_x))*dmvnorm(prev_x, new_x, cov)) )
print(alpha)
u <- runif(1)
if (u<=alpha){
samples[i,]<-new_x
}
else{
samples[i,]<-prev_x
}
}
metropolis_hastings <- function(f, m, x0, cov, dimensions){
#New code
samples <- matrix(vector('integer', dimensions*m), ncol = dimensions)
samples[1,] <- x0
for(i in 2:m){
prev_x <-  samples[i-1,]
new_x <- rmvnorm(1, prev_x, cov)
#print(t(prev_x))
alpha <- min(1, (f(c(new_x))*dmvnorm(new_x, prev_x, cov))/(f(c(prev_x))*dmvnorm(prev_x, new_x, cov)) )
print(alpha)
u <- runif(1)
if (is.nan(alpha)){
samples[i,]<-prev_x
}
if (u<=alpha){
samples[i,]<-new_x
}
else{
samples[i,]<-prev_x
}
}
return (samples)
}
n <- 11
m<-1000
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.01*diag(11), 11)
metropolis_hastings <- function(f, m, x0, cov, dimensions){
#New code
samples <- matrix(vector('integer', dimensions*m), ncol = dimensions)
samples[1,] <- x0
for(i in 2:m){
prev_x <-  samples[i-1,]
new_x <- rmvnorm(1, prev_x, cov)
#print(t(prev_x))
alpha <- min(1, (f(c(new_x))*dmvnorm(new_x, prev_x, cov))/(f(c(prev_x))*dmvnorm(prev_x, new_x, cov)) )
print(alpha)
u <- runif(1)
if (is.nan(alpha)){
samples[i,]<-prev_x
}
else if (u<=alpha){
samples[i,]<-new_x
}
else{
samples[i,]<-prev_x
}
}
return (samples)
}
n <- 11
m<-1000
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.01*diag(11), 11)
p_scenario4 <- function(x){
df <- read.csv("datset.csv", header = TRUE, sep = ",")
#model  <- glm(y ~ X2+X3+X4+X5+X6+X7+X8+X9+X10+X11, family="binomial", data=df)
#y_pred <- predict(model, df[,2:11], type="response")
y_pred <- as.matrix(df[,1:11]) %*% x
return (prod(lr_likelihood(df$y, y_pred))+1000)
}
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.01*diag(11), 11)
setwd("C:/Users/marko/OneDrive/Desktop/M2/Homework5")
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.01*diag(11), 11)
p_scenario4 <- function(x){
df <- read.csv("datset.csv", header = TRUE, sep = ",")
#model  <- glm(y ~ X2+X3+X4+X5+X6+X7+X8+X9+X10+X11, family="binomial", data=df)
#y_pred <- predict(model, df[,2:11], type="response")
y_pred <- as.matrix(df[,1:11]) %*% x
return (prod(lr_likelihood(df$y, y_pred))+1000)
}
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.01*diag(11), 11)
p_scenario4 <- function(x){
df <- read.csv("datset.csv", header = TRUE, sep = ",")
#model  <- glm(y ~ X2+X3+X4+X5+X6+X7+X8+X9+X10+X11, family="binomial", data=df)
#y_pred <- predict(model, df[,2:11], type="response")
y_pred <- as.matrix(df[,1:11]) %*% x
return (prod(lr_likelihood(df$y, y_pred)))
}
metropolis_hastings <- function(f, m, x0, cov, dimensions){
#New code
samples <- matrix(vector('integer', dimensions*m), ncol = dimensions)
samples[1,] <- x0
for(i in 2:m){
prev_x <-  samples[i-1,]
new_x <- rmvnorm(1, prev_x, cov)
#print(t(prev_x))
alpha <- min(1, (f(c(new_x))*dmvnorm(new_x, prev_x, cov))/(f(c(prev_x))*dmvnorm(prev_x, new_x, cov)+0.0000000000001) )
print(alpha)
u <- runif(1)
if (is.nan(alpha)){
samples[i,]<-prev_x
}
else if (u<=alpha){
samples[i,]<-new_x
}
else{
samples[i,]<-prev_x
}
}
return (samples)
}
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.01*diag(11), 11)
metropolis_hastings <- function(f, m, x0, cov, dimensions){
#New code
samples <- matrix(vector('integer', dimensions*m), ncol = dimensions)
samples[1,] <- x0
for(i in 2:m){
prev_x <-  samples[i-1,]
new_x <- rmvnorm(1, prev_x, cov)
print(f(c(prev_x))*dmvnorm(prev_x, new_x, cov))
alpha <- min(1, (f(c(new_x))*dmvnorm(new_x, prev_x, cov))/(f(c(prev_x))*dmvnorm(prev_x, new_x, cov)+0.0000000000001) )
print(alpha)
u <- runif(1)
if (is.nan(alpha)){
samples[i,]<-prev_x
}
else if (u<=alpha){
samples[i,]<-new_x
}
else{
samples[i,]<-prev_x
}
}
return (samples)
}
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.01*diag(11), 11)
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.0001*diag(11), 11)
metropolis_hastings <- function(f, m, x0, cov, dimensions){
#New code
samples <- matrix(vector('integer', dimensions*m), ncol = dimensions)
samples[1,] <- x0
for(i in 2:m){
prev_x <-  samples[i-1,]
new_x <- rmvnorm(1, prev_x, cov)
print(f(c(prev_x))*dmvnorm(prev_x, new_x, cov))
alpha <- min(1, (f(c(new_x))*dmvnorm(new_x, prev_x, cov))/(f(c(prev_x))*dmvnorm(prev_x, new_x, cov)+0.0000000000001) )
u <- runif(1)
if (is.nan(alpha)){
samples[i,]<-prev_x
}
else if (u<=alpha){
samples[i,]<-new_x
}
else{
samples[i,]<-prev_x
}
}
return (samples)
}
metropolis_hastings <- function(f, m, x0, cov, dimensions){
#New code
samples <- matrix(vector('integer', dimensions*m), ncol = dimensions)
samples[1,] <- x0
for(i in 2:m){
prev_x <-  samples[i-1,]
new_x <- rmvnorm(1, prev_x, cov)
print(f(c(prev_x))*dmvnorm(prev_x, new_x, cov))
alpha <- min(1, (f(c(new_x))*dmvnorm(new_x, prev_x, cov))/(f(c(prev_x))*dmvnorm(prev_x, new_x, cov)) )
u <- runif(1)
if (is.nan(alpha)){
samples[i,]<-prev_x
}
else if (u<=alpha){
samples[i,]<-new_x
}
else{
samples[i,]<-prev_x
}
}
return (samples)
}
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.0001*diag(11), 11)
metropolis_hastings <- function(f, m, x0, cov, dimensions){
#New code
samples <- matrix(vector('integer', dimensions*m), ncol = dimensions)
samples[1,] <- x0
for(i in 2:m){
prev_x <-  samples[i-1,]
new_x <- rmvnorm(1, prev_x, cov)
print(f(c(prev_x))*dmvnorm(prev_x, new_x, cov))
alpha <- min(1, (f(c(new_x))*dmvnorm(new_x, prev_x, cov))/(f(c(prev_x))*dmvnorm(prev_x, new_x, cov)) )
u <- runif(1)
if (is.nan(alpha)){
samples[i,]<-prev_x
}
else if (u<=alpha){
samples[i,]<-new_x
}
else{
samples[i,]<-prev_x
}
}
return (samples)
}
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.0001*diag(11), 11)
metropolis_hastings <- function(f, m, x0, cov, dimensions){
#New code
samples <- matrix(vector('integer', dimensions*m), ncol = dimensions)
samples[1,] <- x0
for(i in 2:m){
prev_x <-  samples[i-1,]
new_x <- rmvnorm(1, prev_x, cov)
alpha <- min(1, (f(c(new_x))*dmvnorm(new_x, prev_x, cov))/(f(c(prev_x))*dmvnorm(prev_x, new_x, cov)) )
u <- runif(1)
if (is.nan(alpha)){
samples[i,]<-prev_x
}
else if (u<=alpha){
samples[i,]<-new_x
}
else{
samples[i,]<-prev_x
}
}
return (samples)
}
n <- 11
m<-1000
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.0001*diag(11), 11)
acf(samples, lag.max = 100)
mcse(samples)$se #returns estimate of the mean and
ess(samples)
samples <- metropolis_hastings(p_scenario4, m, c(2.00, -0.84, -0.64,  0.72, -0.10, -0.85, -0.97,  0.23, -0.68, -0.42,  0.47), 0.00001*diag(11), 11)
ess(samples)
p_scenario4_mean()
n <- 11
m<-1000
samples <- metropolis_hastings(p_scenario4, m, c(2.05, -0.87, -0.5,  0.72, -0.09, -1.02, -0.82,  0.24, -0.61, -0.42,  0.47), 0.00001*diag(11), 11)
ess(samples)
samples <- metropolis_hastings(p_scenario4, m, c(2.05, -0.87, -0.5,  0.72, -0.09, -1.02, -0.82,  0.24, -0.61, -0.42,  0.47), 0.001*diag(11), 11)
ess(samples)
samples <- metropolis_hastings(p_scenario4, m, c(2.05, -0.87, -0.5,  0.72, -0.09, -1.02, -0.82,  0.24, -0.61, -0.42,  0.47), 0.0005*diag(11), 11)
ess(samples)
samples <- metropolis_hastings(p_scenario4, m, c(2.05, -0.87, -0.5,  0.72, -0.09, -1.02, -0.82,  0.24, -0.61, -0.42,  0.47), 0.000000000005*diag(11), 11)
ess(samples)
samples <- metropolis_hastings(p_scenario4, m, c(2.05, -0.87, -0.5,  0.72, -0.09, -1.02, -0.82,  0.24, -0.61, -0.42,  0.47), 0.000005*diag(11), 11)
ess(samples)
mean(samples)
mean(samples,1)
mean(samples,0)
