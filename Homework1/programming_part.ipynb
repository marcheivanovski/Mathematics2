{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Area of triangle defined with parameter points\n",
    "def area(x1, y1, x2, y2, x3, y3):\n",
    "    return abs((x1 * (y2 - y3) + x2 * (y3 - y1)\n",
    "                + x3 * (y1 - y2)) / 2.0)\n",
    "\n",
    "#Function which returns True when point (x,y) is inside the triangle defines with points 1,2,3\n",
    "def isInside(x1, y1, x2, y2, x3, y3, x, y):\n",
    "\n",
    "    # Calculate area of triangle ABC\n",
    "    A = area (x1, y1, x2, y2, x3, y3)\n",
    " \n",
    "    # Calculate area of triangle PBC\n",
    "    A1 = area (x, y, x2, y2, x3, y3)\n",
    "     \n",
    "    # Calculate area of triangle PAC\n",
    "    A2 = area (x1, y1, x, y, x3, y3)\n",
    "     \n",
    "    # Calculate area of triangle PAB\n",
    "    A3 = area (x1, y1, x2, y2, x, y)\n",
    "     \n",
    "    # Check if sum of A1, A2 and A3\n",
    "    # is same as A\n",
    "    if(A == A1 + A2 + A3):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "#Vector abs\n",
    "def absolute_vector(x):\n",
    "    return math.sqrt(x[0]**2+x[1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next are all the projection functions\n",
    "def pd1(x,y):\n",
    "    if x**2+y**2<=1.5:\n",
    "        return x,y\n",
    "    else:\n",
    "        return ( x*math.sqrt(1.5)/math.sqrt(x**2+y**2),y*math.sqrt(1.5)/math.sqrt(x**2+y**2) )\n",
    "    \n",
    "def pd2_map_single(x):\n",
    "    if abs(x)<=1:\n",
    "        return x\n",
    "    elif x>1:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def pd2(x,y):\n",
    "    if abs(x)<=1 and abs(y)<=1:\n",
    "        return (x,y)\n",
    "    else:\n",
    "        return (pd2_map_single(x), pd2_map_single(y))\n",
    "\n",
    "\n",
    "def pd3(x,y):\n",
    "    if -1<=x and x<= 1.5 and -1<=y and y<= 1.5 and y<=0.5-x:\n",
    "        return (x,y)\n",
    "    elif -1<=y and y<=1.5 and x<-1:\n",
    "        return (-1,y)\n",
    "    elif -1<=x and x<=1.5 and y<-1:\n",
    "        return (x,-1)\n",
    "    elif x<-1 and y<-1:\n",
    "        return (-1,-1)\n",
    "    elif y>1.5 and y>x+2.5:\n",
    "        return (-1,1.5)\n",
    "    elif x>1.5 and y<x-2.5:\n",
    "        return (1.5, -1)\n",
    "    else:\n",
    "        return (1/2*(x-y+0/5), 1/2*(1/2+y-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function which we are optimizing\n",
    "def f(X):\n",
    "    x=X[0]; y=X[1]\n",
    "    return x**2+math.exp(x)+y**2-x*y\n",
    "\n",
    "#The gradient of the function evaluated at x,y\n",
    "def gradient_step(x,y):\n",
    "    return np.array([2*x+math.exp(x)-y,2*y-x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1_1:\n",
    "This case uses the circle constrain domain and the fact that f is L-lipschitz.\n",
    "\n",
    "$D: x^2+y^2<=1.5$\n",
    "\n",
    "$\\gamma=\\frac{|x_{1}-x_{*}|}{L\\sqrt{T}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([-1,1])\n",
    "x_star=np.array([-0.432563, -0.216281])\n",
    "\n",
    "T=11\n",
    "L=14.67\n",
    "gamma=absolute_vector(x-x_star)/(L*math.sqrt(T))\n",
    "\n",
    "all_points11=[x]\n",
    "for i in range(1,11):\n",
    "    x_new=x-gamma*np.array(gradient_step(x[0],x[1]))\n",
    "    x=np.array(pd1( x_new[0], x_new[1] ))\n",
    "    all_points11.append(x)\n",
    "#all_points11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuall best is: [-0.432563 -0.216281], PGD returned: [-0.50593927  0.3841299 ], difference in f: -0.41163867582559155.\n"
     ]
    }
   ],
   "source": [
    "print(f'Actuall best is: {x_star}, PGD returned: {all_points11[10]}, difference in f: {f(x_star)-f(all_points11[10])}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1_2:\n",
    "This case uses the circle constrain domain and the fact that f is $\\beta$-smooth.\n",
    "\n",
    "$D: x^2+y^2<=1.5$ \n",
    "\n",
    "$\\gamma=\\frac{1}{\\beta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([-1,1])\n",
    "\n",
    "beta=9.522\n",
    "gamma=1/beta\n",
    "\n",
    "all_points12=[x]\n",
    "for i in range(1,11):\n",
    "    x_new=x-gamma*np.array(gradient_step(x[0],x[1]))\n",
    "    x=np.array(pd1( x_new[0], x_new[1] ))\n",
    "    all_points12.append(x)\n",
    "#all_points12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuall best is: [-0.432563 -0.216281], PGD returned: [-0.3556857  -0.08413374], difference in f: -0.015181412782638182\n"
     ]
    }
   ],
   "source": [
    "print(f'Actuall best is: {x_star}, PGD returned: {all_points12[10]}, difference in f: {f(x_star)-f(all_points12[10])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1_3:\n",
    "This case uses the circle constrain domain and the fact that f is $\\alpha$-strongly convex and L-lipschitz.\n",
    "\n",
    "$D: x^2+y^2<=1.5$ \n",
    "\n",
    "$\\gamma_{k}=\\frac{2}{\\alpha(k+1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([-1,1])\n",
    "\n",
    "beta=9.522\n",
    "alpha=1.07\n",
    "\n",
    "all_points13=[x]\n",
    "for i in range(1,11):\n",
    "    gamma=2/(alpha*(i+1))\n",
    "    x_new=x-gamma*np.array(gradient_step(x[0],x[1]))\n",
    "    x=np.array(pd1( x_new[0], x_new[1] ))\n",
    "    all_points13.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuall best is: [-0.432563 -0.216281], PGD returned: [-0.43406103 -0.21835227], difference in f: -4.15856668500858e-06\n"
     ]
    }
   ],
   "source": [
    "print(f'Actuall best is: {x_star}, PGD returned: {all_points13[10]}, difference in f: {f(x_star)-f(all_points13[10])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the circle domain the adaptive gamma returns the best results!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2_1:\n",
    "This case uses the square constrain domain and the fact that f is L-lipschitz.\n",
    "\n",
    "$D: [-1,1]x[-1,1]$\n",
    "\n",
    "$\\gamma=\\frac{|x_{1}-x_{*}|}{L\\sqrt{T}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([-1,1])\n",
    "\n",
    "T=11\n",
    "L=14.67\n",
    "gamma=absolute_vector(x-x_star)/(L*math.sqrt(T))\n",
    "\n",
    "all_points21=[x]\n",
    "for i in range(1,11):\n",
    "    x_new=x-gamma*np.array(gradient_step(x[0],x[1]))\n",
    "    x=np.array(pd2( x_new[0], x_new[1] ))\n",
    "    all_points21.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuall best is: [-0.432563 -0.216281], PGD returned: [-0.52831125  0.41020396], difference in f: -0.46451820682723055\n"
     ]
    }
   ],
   "source": [
    "print(f'Actuall best is: {x_star}, PGD returned: {all_points21[10]}, difference in f: {f(x_star)-f(all_points21[10])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2_2:\n",
    "This case uses the square constrain domain and the fact that f is $\\beta$-smooth.\n",
    "\n",
    "$D: [-1,1]x[-1,1]$\n",
    "\n",
    "$\\gamma=\\frac{1}{\\beta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([-1,1])\n",
    "\n",
    "beta=9.522\n",
    "gamma=1/beta\n",
    "\n",
    "all_points22=[x]\n",
    "for i in range(1,11):\n",
    "    x_new=x-gamma*np.array(gradient_step(x[0],x[1]))\n",
    "    x=np.array(pd2( x_new[0], x_new[1] ))\n",
    "    all_points22.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuall best is: [-0.432563 -0.216281], PGD returned: [-0.3556857  -0.08413374], difference in f: -0.015181412782638182\n"
     ]
    }
   ],
   "source": [
    "print(f'Actuall best is: {x_star}, PGD returned: {all_points22[10]}, difference in f: {f(x_star)-f(all_points22[10])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2_3:\n",
    "This case uses the square constrain domain and the fact that f is $\\alpha$-strongly convex and L-lipschitz.\n",
    "$D: [-1,1]x[-1,1]$\n",
    "\n",
    "$\\gamma_{k}=\\frac{2}{\\alpha(k+1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([-1,1])\n",
    "\n",
    "beta=9.522\n",
    "alpha=1.07\n",
    "\n",
    "all_points23=[x]\n",
    "for i in range(1,11):\n",
    "    gamma=2/(alpha*(i+1))\n",
    "    x_new=x-gamma*np.array(gradient_step(x[0],x[1]))\n",
    "    x=np.array(pd2( x_new[0], x_new[1] ))\n",
    "    all_points23.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuall best is: [-0.432563 -0.216281], PGD returned: [-0.42753403 -0.20936829], difference in f: -4.6532596709281115e-05\n"
     ]
    }
   ],
   "source": [
    "print(f'Actuall best is: {x_star}, PGD returned: {all_points23[10]}, difference in f: {f(x_star)-f(all_points23[10])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this domain , yet again the adaptive gamma is the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3_1:\n",
    "This case uses the triangle constrain domain and the fact that f is L-lipschitz.\n",
    "\n",
    "D: Triangle defined with (-1,1.5), (1.5,-1), (-1,-1)\n",
    "\n",
    "$\\gamma=\\frac{|x_{1}-x_{*}|}{L\\sqrt{T}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([-1,1])\n",
    "\n",
    "T=11\n",
    "L=14.67\n",
    "gamma=absolute_vector(x-x_star)/(L*math.sqrt(T))\n",
    "\n",
    "all_points31=[x]\n",
    "for i in range(1,11):\n",
    "    x_new=x-gamma*np.array(gradient_step(x[0],x[1]))\n",
    "    x=np.array(pd3( x_new[0], x_new[1] ))\n",
    "    all_points31.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuall best is: [-0.432563 -0.216281], PGD returned: [-0.52831125  0.41020396], difference in f: -0.46451820682723055\n"
     ]
    }
   ],
   "source": [
    "print(f'Actuall best is: {x_star}, PGD returned: {all_points31[10]}, difference in f: {f(x_star)-f(all_points31[10])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3_2:\n",
    "This case uses the triangle constrain domain and the fact that f is $\\beta$-smooth.\n",
    "\n",
    "D: Triangle defined with (-1,1.5), (1.5,-1), (-1,-1)\n",
    "\n",
    "$\\gamma=\\frac{1}{\\beta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([-1,1])\n",
    "\n",
    "beta=9.522\n",
    "gamma=1/beta\n",
    "\n",
    "all_points32=[x]\n",
    "for i in range(1,11):\n",
    "    x_new=x-gamma*np.array(gradient_step(x[0],x[1]))\n",
    "    x=np.array(pd3( x_new[0], x_new[1] ))\n",
    "    all_points32.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuall best is: [-0.432563 -0.216281], PGD returned: [-0.3556857  -0.08413374], difference in f: -0.015181412782638182\n"
     ]
    }
   ],
   "source": [
    "print(f'Actuall best is: {x_star}, PGD returned: {all_points32[10]}, difference in f: {f(x_star)-f(all_points32[10])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3_3:\n",
    "\n",
    "This case uses the triangle constrain domain and the fact that f is $\\alpha$-strongly convex and L-lipschitz.\n",
    "\n",
    "D: Triangle defined with (-1,1.5), (1.5,-1), (-1,-1)\n",
    "\n",
    "$\\gamma_{k}=\\frac{2}{\\alpha(k+1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([-1,1])\n",
    "\n",
    "beta=9.522\n",
    "alpha=1.07\n",
    "\n",
    "all_points33=[x]\n",
    "for i in range(1,11):\n",
    "    gamma=2/(alpha*(i+1))\n",
    "    x_new=x-gamma*np.array(gradient_step(x[0],x[1]))\n",
    "    x=np.array(pd3( x_new[0], x_new[1] ))\n",
    "    all_points33.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actuall best is: [-0.432563 -0.216281], PGD returned: [-0.4253522  -0.20635954], difference in f: -9.58010770396589e-05\n"
     ]
    }
   ],
   "source": [
    "print(f'Actuall best is: {x_star}, PGD returned: {all_points33[10]}, difference in f: {f(x_star)-f(all_points33[10])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One more time the fourth equation shows as the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical guarantees vs actual obtained results\n",
    "\n",
    "In the following part I calculated the theoretical guarantees from Theorem 3.3 from the lecture notes and calculated the left part of the inequations for all corresponding 9 combinations performed. Essentialy, the smaller the left part the smaller minimum we obtain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First inequality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equation guarantee is: 5.9364896569245476, the left side of the equation for all three domains are:\n",
      "     -circle domain: 1.0321992420877533,\n",
      "     -square domain: 1.1577968902705496,\n",
      "     -triangular domain: 1.1577968902705496.\n"
     ]
    }
   ],
   "source": [
    "ineq1=L*absolute_vector(all_points11[0] - x_star)/math.sqrt(11)\n",
    "left_11=f(np.sum(all_points11, axis=0)/11)-f(x_star)\n",
    "left_21=f(np.sum(all_points21, axis=0)/11)-f(x_star)\n",
    "left_31=f(np.sum(all_points31, axis=0)/11)-f(x_star)\n",
    "print(f'Equation guarantee is: {ineq1}, the left side of the equation for all three domains are:\\n \\\n",
    "    -circle domain: {left_11},\\n \\\n",
    "    -square domain: {left_21},\\n \\\n",
    "    -triangular domain: {left_31}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are smaller than the guarantee and the circle domain returnes the smallest margin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second inequality\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equation guarantee is: 4.912302733753495, the left side of the equation for all three domains are:\n",
      "     -circle domain: 0.015181412782638182,\n",
      "     -square domain: 0.015181412782638182,\n",
      "     -triangular domain: 0.015181412782638182.\n"
     ]
    }
   ],
   "source": [
    "beta=9.522\n",
    "ineq2=(3*beta*absolute_vector(all_points11[0] - x_star)**2+f(all_points11[0])-f(x_star))/11\n",
    "left_12=f(all_points12[10])-f(x_star)\n",
    "left_22=f(all_points22[10])-f(x_star)\n",
    "left_32=f(all_points32[10])-f(x_star)\n",
    "print(f'Equation guarantee is: {ineq2}, the left side of the equation for all three domains are:\\n \\\n",
    "    -circle domain: {left_12},\\n \\\n",
    "    -square domain: {left_22},\\n \\\n",
    "    -triangular domain: {left_32}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the domains return pretty much the same result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth inequality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equation guarantee is: 33.52163551401869, the left side of the equation for all three domains are:\n",
      "     -circle domain: 6.177207223823089e-05,\n",
      "     -square domain: 0.003365609811613046,\n",
      "     -triangular domain: 0.007247069159252217.\n"
     ]
    }
   ],
   "source": [
    "alpha=1.07\n",
    "L=14.67\n",
    "T=11\n",
    "ineq3=(2*L**2)/(alpha*(12))\n",
    "left_13=f( sum([2*(i+1)/(11*(11+1))*xi for i,xi in enumerate(all_points13)]) )-f(x_star)\n",
    "left_23=f( sum([2*(i+1)/(11*(11+1))*xi for i,xi in enumerate(all_points23)]) )-f(x_star)\n",
    "left_33=f( sum([2*(i+1)/(11*(11+1))*xi for i,xi in enumerate(all_points33)]) )-f(x_star)\n",
    "print(f'Equation guarantee is: {ineq3}, the left side of the equation for all three domains are:\\n \\\n",
    "    -circle domain: {left_13},\\n \\\n",
    "    -square domain: {left_23},\\n \\\n",
    "    -triangular domain: {left_33}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fourth equation underestimates by a lot, but square is the best!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How close did we get to x*\n",
    "In the following part, I calculated how close all 9 combinations came to x*. Essentialy, I calculated $|x_{11}-x_{*}|$ for all final points obtained from all PGDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How close did we get on the circular domain:\n",
      "     -using learning rate from the first equality:0.6048779415773553,\n",
      "     -using learning rate from the second equality:0.15288236795052068,\n",
      "     -using learning rate from the fourth equality:0.0025562195781356854.\n",
      "How close did we get on the squared domain:\n",
      "     -using learning rate from the first equality:0.6337595179436561,\n",
      "     -using learning rate from the second equality:0.15288236795052068,\n",
      "     -using learning rate from the fourth equality:0.008548453592554486.\n",
      "How close did we get on the triangular domain:\n",
      "     -using learning rate from the first equality:0.6337595179436561,\n",
      "     -using learning rate from the second equality:0.15288236795052068,\n",
      "     -using learning rate from the fourth equality:0.012265035733508785.\n"
     ]
    }
   ],
   "source": [
    "print(f'How close did we get on the circular domain:\\n \\\n",
    "    -using learning rate from the first equality:{absolute_vector(all_points11[10]-x_star)},\\n \\\n",
    "    -using learning rate from the second equality:{absolute_vector(all_points12[10]-x_star)},\\n \\\n",
    "    -using learning rate from the fourth equality:{absolute_vector(all_points13[10]-x_star)}.')\n",
    "\n",
    "print(f'How close did we get on the squared domain:\\n \\\n",
    "    -using learning rate from the first equality:{absolute_vector(all_points21[10]-x_star)},\\n \\\n",
    "    -using learning rate from the second equality:{absolute_vector(all_points22[10]-x_star)},\\n \\\n",
    "    -using learning rate from the fourth equality:{absolute_vector(all_points23[10]-x_star)}.')\n",
    "\n",
    "print(f'How close did we get on the triangular domain:\\n \\\n",
    "    -using learning rate from the first equality:{absolute_vector(all_points31[10]-x_star)},\\n \\\n",
    "    -using learning rate from the second equality:{absolute_vector(all_points32[10]-x_star)},\\n \\\n",
    "    -using learning rate from the fourth equality:{absolute_vector(all_points33[10]-x_star)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results it is far obvious that using the learning rate from the fourth inequality resulted in the closest point to x* which should not come at any surprise, since it is adaptive on every step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([\n",
    "    [3, 10, 30],\n",
    "    [0.1, 10, 35],\n",
    "    [3, 10, 30],\n",
    "    [0.1, 10, 35]\n",
    "    ])\n",
    "c = np.array([1, 1.2, 3, 3.2])\n",
    "p = np.array([\n",
    "    [0.36890, 0.1170, 0.2673],\n",
    "    [0.46990, 0.4387, 0.7470],\n",
    "    [0.10910, 0.8732, 0.5547],\n",
    "    [0.03815, 0.5743, 0.8828]\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(z):\n",
    "    final_sum=0\n",
    "    for i in range(4):\n",
    "        exponent_sum=0\n",
    "        for j in range(3):\n",
    "            exponent_sum-=a[i][j]*(z[j]-p[i][j])**2\n",
    "        final_sum-=c[i]*math.exp(exponent_sum)\n",
    "    return final_sum\n",
    "\n",
    "def f_gradient(z):\n",
    "    \n",
    "    final_sum=[0,0,0]\n",
    "    for i in range(4):\n",
    "        \n",
    "        exponent_sum=0\n",
    "        for j in range(3):\n",
    "            exponent_sum-=a[i][j]*(z[j]-p[i][j])**2\n",
    "        \n",
    "        k=0\n",
    "        final_sum[k]+=c[i]*math.exp(exponent_sum)*2*a[i][k]*(z[k]-p[i][k]) \n",
    "        k=1\n",
    "        final_sum[k]+=c[i]*math.exp(exponent_sum)*2*a[i][k]*(z[k]-p[i][k])  \n",
    "        k=2\n",
    "        final_sum[k]+=c[i]*math.exp(exponent_sum)*2*a[i][k]*(z[k]-p[i][k])  \n",
    "        \n",
    "    return np.array(final_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(gamma, z, niter):\n",
    "    #all_points=[z]\n",
    "    for i in range(1,niter):\n",
    "        z=z-gamma*f_gradient(z)\n",
    "        #z=np.array(pd( z_new[0], z_new[1], z_new[2] ))\n",
    "        #all_points.append(z)\n",
    "    return z\n",
    "\n",
    "#for i in all_points:\n",
    "#    print(f'New points:{list(i)}, the value of f at them:{f(i)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha=0.01 and 1000 iterations we got -3.862782147818607,\n",
      "     which is 2.1529444893531036e-12 away from the real minimum of f\n"
     ]
    }
   ],
   "source": [
    "actual_min=-3.86278214782076\n",
    "alpha=0.01; z=np.array([0.5,0.5,0.5]); niter=1000\n",
    "score=f(pgd(alpha, np.array([0.5,0.5,0.5]), niter))\n",
    "print(f'Using alpha={alpha} and {niter} iterations we got {score},\\n \\\n",
    "    which is {abs(score-actual_min)} away from the real minimum of f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha=0.1 and 1000 iterations we got -1.8965338597606195e-16,\n",
      "     which is 3.86278214782076 away from the real minimum of f\n"
     ]
    }
   ],
   "source": [
    "alpha=0.1; z=np.array([0.5,0.5,0.5]); niter=1000\n",
    "score=f(pgd(alpha, np.array([0.5,0.5,0.5]), niter))\n",
    "print(f'Using alpha={alpha} and {niter} iterations we got {score},\\n \\\n",
    "    which is {abs(score-actual_min)} away from the real minimum of f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using alpha=0.01 and 100 iterations we got -3.855864223369109,\n",
      "     which is 0.006917924451650848 away from the real minimum of f\n"
     ]
    }
   ],
   "source": [
    "alpha=0.01; z=np.array([0.5,0.5,0.5]); niter=100\n",
    "score=f(pgd(alpha, np.array([0.5,0.5,0.5]), niter))\n",
    "print(f'Using alpha={alpha} and {niter} iterations we got {score},\\n \\\n",
    "    which is {abs(score-actual_min)} away from the real minimum of f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managed to get pretty close to the real x* by using alpha=0.01 and 1000 iterations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ids-clone] *",
   "language": "python",
   "name": "conda-env-ids-clone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
